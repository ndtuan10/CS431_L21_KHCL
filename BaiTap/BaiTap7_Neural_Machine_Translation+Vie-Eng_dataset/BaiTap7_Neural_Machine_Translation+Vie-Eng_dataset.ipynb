{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural-Machine-Translation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMAm8f9B3T7+elTXZUEZz3n",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ndtuan10/DeepLearning_CS431.L21.KHCL/blob/main/BaiTap/BaiTap7_Neural_Machine_Translation%2BVie-Eng_dataset/BaiTap7_Neural_Machine_Translation%2BVie-Eng_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9usIbl6Fyfy7"
      },
      "source": [
        "# **BÀI TẬP 7**\n",
        "\n",
        "**Môn : Các kỹ thuật học sâu và ứng dụng - CS431.L21.KHCL**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frM2YgR33PQj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f9e8e5a-c350-4c3b-902b-95f238ae8d78"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-poTCY2gy5Bi"
      },
      "source": [
        "# **Neural Machine Translation (NMT) - Translating Vietnamese sentences to English sentences**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qkqija1KzkXY"
      },
      "source": [
        "## **What are we going to do?**\n",
        "We will basically create an encoder-decoder LSTM model using [Keras Functional API](https://www.tensorflow.org/alpha/guide/keras/functional) ( with [TensorFlow](https://www.tensorflow.org/) ). We will convert the Vietnamese sentences to English sentences.\n",
        "\n",
        "Here's an example,\n",
        "\n",
        "con mèo ngủ giữa những con chó -> the cat sleeps among the dogs  \n",
        "\n",
        "So, let's get started.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Li9J3U2QLK3"
      },
      "source": [
        "# **I. Preparing the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S_u7Cswzqep"
      },
      "source": [
        "## **1) Importing the libraries**\n",
        "\n",
        "We will import TensorFlow and Keras. From Keras, we import various modules which help in building NN layers, preprocess data and construct LSTM models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjFNktGwzzKz"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers , activations , models , preprocessing , utils\n",
        "import pandas as pd"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkI8Ra7-zqpK"
      },
      "source": [
        "## **2) Reading the data**\n",
        "\n",
        "\n",
        "Our dataset which contains more than 7K pairs of Vietnamese-English phrases. This amazing dataset is available at http://www.manythings.org/anki/ and it also other 50+ sets of bilingual sentences. We download the dataset for Vietnamese-English phrases, unzip it and read it using [Pandas](https://pandas.pydata.org/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "--pj4w5qz8Bl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f31e26f-36c3-4e47-9087-40ebfb785591"
      },
      "source": [
        "'''!wget http://www.manythings.org/anki/vie-eng.zip\n",
        "!unzip vie-eng.zip'''"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'!wget http://www.manythings.org/anki/vie-eng.zip\\n!unzip vie-eng.zip'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8owW0_q0B1q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "92a2882b-e684-4e12-c037-9d8c93b5126f"
      },
      "source": [
        "f = open('/content/drive/MyDrive/Các kỹ thuật học sâu - CS431/Machine Translation/vie-eng/vie.txt','r')\n",
        "lines = pd.read_table(f , names=[ 'eng' , 'vie' ] )\n",
        "print(lines.shape)\n",
        "lines.reset_index( level=0 , inplace=True )\n",
        "lines.rename( columns={ 'index' : 'eng' , 'eng' : 'vie' , 'vie' : 'c' } , inplace=True )\n",
        "lines = lines.drop( 'c' , 1 )\n",
        "lines.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7523, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>eng</th>\n",
              "      <th>vie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Chạy!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Help!</td>\n",
              "      <td>Giúp tôi với!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Go on.</td>\n",
              "      <td>Tiếp tục đi.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Hello!</td>\n",
              "      <td>Chào bạn.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Hurry!</td>\n",
              "      <td>Nhanh lên nào!</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      eng             vie\n",
              "0    Run!           Chạy!\n",
              "1   Help!   Giúp tôi với!\n",
              "2  Go on.    Tiếp tục đi.\n",
              "3  Hello!       Chào bạn.\n",
              "4  Hurry!  Nhanh lên nào!"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1YleZ3rVzqx3"
      },
      "source": [
        "## **3) Preparing input data for the Encoder ( `encoder_input_data` )**\n",
        "The Encoder model will be fed input data which are preprocessed Vietnamese sentences. The preprocessing is done as follows :\n",
        "\n",
        "\n",
        "1.   Tokenizing the Vietnamese sentences from `vie_lines`.\n",
        "2.   Determining the maximum length of the Vietnamese sentence that's `max_input_length`.\n",
        "3.   Padding the `tokenized_vie_lines` to the max_input_length.\n",
        "4.   Determining the vocabulary size ( `num_vie_tokens` ) for Vietnamese words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blXweHph0Ogf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4c48785-4347-489f-93bd-7308ebf47970"
      },
      "source": [
        "vie_lines = list()\n",
        "for line in lines.vie:\n",
        "    vie_lines.append( line ) \n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( vie_lines ) \n",
        "tokenized_vie_lines = tokenizer.texts_to_sequences( vie_lines ) \n",
        "\n",
        "length_list = list()\n",
        "for token_seq in tokenized_vie_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_input_length = np.array( length_list ).max()\n",
        "print( 'Vietnamese max length is {}'.format( max_input_length ))\n",
        "\n",
        "padded_vie_lines = preprocessing.sequence.pad_sequences( tokenized_vie_lines , maxlen=max_input_length , padding='post' )\n",
        "encoder_input_data = np.array( padded_vie_lines )\n",
        "print( 'Encoder input data shape -> {}'.format( encoder_input_data.shape ))\n",
        "\n",
        "vie_word_dict = tokenizer.word_index\n",
        "num_vie_tokens = len( vie_word_dict )+1\n",
        "print( 'Number of Vietnamese tokens = {}'.format( num_vie_tokens))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vietnamese max length is 41\n",
            "Encoder input data shape -> (7523, 41)\n",
            "Number of Vietnamese tokens = 2359\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdDSeCjYzq1Q"
      },
      "source": [
        "## **4) Preparing input data for the Decoder ( `decoder_input_data` )**\n",
        "The Decoder model will be fed the preprocessed English lines. The preprocessing steps are similar to the ones which are above. This one step is carried out before the other steps.\n",
        "\n",
        "\n",
        "*   Append `<START>` tag at the first position in  each English sentence.\n",
        "*   Append `<END>` tag at the last position in  each English sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoFdrc_f0amK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d7611d8-2be8-448d-b25a-4711bfda7753"
      },
      "source": [
        "eng_lines = list()\n",
        "for line in lines.eng:\n",
        "    eng_lines.append( '<START> ' + line + ' <END>' )  \n",
        "\n",
        "tokenizer = preprocessing.text.Tokenizer()\n",
        "tokenizer.fit_on_texts( eng_lines ) \n",
        "tokenized_eng_lines = tokenizer.texts_to_sequences( eng_lines ) \n",
        "\n",
        "length_list = list()\n",
        "for token_seq in tokenized_eng_lines:\n",
        "    length_list.append( len( token_seq ))\n",
        "max_output_length = np.array( length_list ).max()\n",
        "print( 'English max length is {}'.format( max_output_length ))\n",
        "\n",
        "padded_eng_lines = preprocessing.sequence.pad_sequences( tokenized_eng_lines , maxlen=max_output_length, padding='post' )\n",
        "decoder_input_data = np.array( padded_eng_lines )\n",
        "print( 'Decoder input data shape -> {}'.format( decoder_input_data.shape ))\n",
        "\n",
        "eng_word_dict = tokenizer.word_index\n",
        "num_eng_tokens = len( eng_word_dict )+1\n",
        "print( 'Number of English tokens = {}'.format( num_eng_tokens))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English max length is 34\n",
            "Decoder input data shape -> (7523, 34)\n",
            "Number of English tokens = 3710\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jkWh07Ph0hZv"
      },
      "source": [
        "## **5) Preparing target data for the Decoder ( decoder_target_data )** \n",
        "\n",
        "We take a copy of `tokenized_eng_lines` and modify it like this.\n",
        "\n",
        "\n",
        "\n",
        "1.   We remove the `<start>` tag which we appended earlier. Hence, the word ( which is `<start>` in this case  ) will be removed.\n",
        "2.   Convert the `padded_eng_lines` ( ones which do not have `<start>` tag ) to one-hot vectors.\n",
        "\n",
        "For example :\n",
        "\n",
        "```\n",
        " [ '<start>' , 'xin' , 'chào' , '<end>' ]\n",
        "\n",
        "```\n",
        "\n",
        "wil become \n",
        "\n",
        "```\n",
        " [ 'xin' , 'chào' , '<end>' ]\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nhS6J-z0ezV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "793057f9-bceb-4f75-b4a7-a99de4571fa1"
      },
      "source": [
        "decoder_target_data = list()\n",
        "for token_seq in tokenized_eng_lines:\n",
        "    decoder_target_data.append( token_seq[ 1 : ] ) \n",
        "    \n",
        "padded_eng_lines = preprocessing.sequence.pad_sequences( decoder_target_data , maxlen=max_output_length, padding='post' )\n",
        "onehot_eng_lines = utils.to_categorical( padded_eng_lines , num_eng_tokens )\n",
        "decoder_target_data = np.array( onehot_eng_lines )\n",
        "print( 'Decoder target data shape -> {}'.format( decoder_target_data.shape ))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Decoder target data shape -> (7523, 34, 3710)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cb5Z9iFZ0YLu"
      },
      "source": [
        "# **II. Defining and Training the models**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbqc6Tlk0Yd5"
      },
      "source": [
        "## **1) Defining the Encoder-Decoder model**\n",
        "- The model will have Embedding, LSTM and Dense layers. The basic configuration is as follows.\n",
        "\n",
        "\n",
        "*   2 Input Layers : One for `encoder_input_data` and another for `decoder_input_data`.\n",
        "*   Embedding layer : For converting token vectors to fix sized dense vectors. **( Note :  Don't forget the `mask_zero=True` argument here )**\n",
        "*   LSTM layer : Provide access to Long-Short Term cells.\n",
        "\n",
        "Working : \n",
        "\n",
        "1.   The `encoder_input_data` comes in the Embedding layer (  `encoder_embedding` ). \n",
        "2.   The output of the Embedding layer goes to the LSTM cell which produces 2 state vectors ( `h` and `c` which are `encoder_states` )\n",
        "3.   These states are set in the LSTM cell of the decoder.\n",
        "4.   The decoder_input_data comes in through the Embedding layer.\n",
        "5.   The Embeddings goes in LSTM cell ( which had the states ) to produce seqeuences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PNeNbC3c0x4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e46d96d-539a-475f-8279-5a9928a51bbf"
      },
      "source": [
        "encoder_inputs = tf.keras.layers.Input(shape=( None , ))\n",
        "encoder_embedding = tf.keras.layers.Embedding( num_vie_tokens, 256 , mask_zero=True ) (encoder_inputs)\n",
        "encoder_outputs , state_h , state_c = tf.keras.layers.LSTM( 128 , return_state=True  )( encoder_embedding )\n",
        "encoder_states = [ state_h , state_c ]\n",
        "\n",
        "decoder_inputs = tf.keras.layers.Input(shape=( None ,  ))\n",
        "decoder_embedding = tf.keras.layers.Embedding( num_eng_tokens, 256 , mask_zero=True) (decoder_inputs)\n",
        "decoder_lstm = tf.keras.layers.LSTM( 128 , return_state=True , return_sequences=True)\n",
        "decoder_outputs , _ , _ = decoder_lstm ( decoder_embedding , initial_state=encoder_states )\n",
        "decoder_dense = tf.keras.layers.Dense( num_eng_tokens , activation=tf.keras.activations.softmax ) \n",
        "output = decoder_dense ( decoder_outputs )\n",
        "\n",
        "model = tf.keras.models.Model([encoder_inputs, decoder_inputs], output )\n",
        "model.compile(optimizer=tf.keras.optimizers.RMSprop(), loss='categorical_crossentropy')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, None)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, None, 256)    603904      input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "embedding_1 (Embedding)         (None, None, 256)    949760      input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm (LSTM)                     [(None, 128), (None, 197120      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "lstm_1 (LSTM)                   [(None, None, 128),  197120      embedding_1[0][0]                \n",
            "                                                                 lstm[0][1]                       \n",
            "                                                                 lstm[0][2]                       \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, None, 3710)   478590      lstm_1[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 2,426,494\n",
            "Trainable params: 2,426,494\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJW4gsmc0Yfn"
      },
      "source": [
        "## **2) Training the model**\n",
        "- We train the model for a number of epochs with RMSprop optimizer and categorical crossentropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EOeL48m04MZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eff6a712-bffa-4cf7-eb69-36b9e5bd1740"
      },
      "source": [
        "import time\n",
        "start = time.time()\n",
        "model.fit([encoder_input_data , decoder_input_data], decoder_target_data, batch_size=250, epochs=100) \n",
        "stop = time.time()\n",
        "time = {stop - start}\n",
        "print(f\"Training time: {time} s\") \n",
        "model.save( 'model.h5' ) "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 11s 104ms/step - loss: 1.5353\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 1.3101\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 1.2443\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 1.1909\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 1.1532\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 1.1242\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 1.0941\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 3s 97ms/step - loss: 1.0669\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 1.0392\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 1.0114\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.9852\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.9608\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.9366\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.9137\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.8925\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.8726\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.8533\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.8355\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.8174\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.8017\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.7848\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.7696\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.7545\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.7389\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.7256\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.7114\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.6967\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.6832\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.6696\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.6562\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.6437\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.6299\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.6175\n",
            "Epoch 34/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.6044\n",
            "Epoch 35/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.5921\n",
            "Epoch 36/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.5795\n",
            "Epoch 37/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.5677\n",
            "Epoch 38/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.5553\n",
            "Epoch 39/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.5435\n",
            "Epoch 40/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.5313\n",
            "Epoch 41/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.5198\n",
            "Epoch 42/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.5083\n",
            "Epoch 43/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.4971\n",
            "Epoch 44/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.4856\n",
            "Epoch 45/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.4746\n",
            "Epoch 46/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.4638\n",
            "Epoch 47/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.4524\n",
            "Epoch 48/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.4428\n",
            "Epoch 49/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.4318\n",
            "Epoch 50/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.4224\n",
            "Epoch 51/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.4121\n",
            "Epoch 52/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.4027\n",
            "Epoch 53/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.3922\n",
            "Epoch 54/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.3833\n",
            "Epoch 55/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.3740\n",
            "Epoch 56/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.3651\n",
            "Epoch 57/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.3558\n",
            "Epoch 58/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.3464\n",
            "Epoch 59/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.3379\n",
            "Epoch 60/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.3298\n",
            "Epoch 61/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.3215\n",
            "Epoch 62/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.3130\n",
            "Epoch 63/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.3052\n",
            "Epoch 64/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.2970\n",
            "Epoch 65/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.2900\n",
            "Epoch 66/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.2814\n",
            "Epoch 67/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.2743\n",
            "Epoch 68/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.2672\n",
            "Epoch 69/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.2604\n",
            "Epoch 70/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.2533\n",
            "Epoch 71/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.2459\n",
            "Epoch 72/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.2402\n",
            "Epoch 73/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.2330\n",
            "Epoch 74/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.2267\n",
            "Epoch 75/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.2204\n",
            "Epoch 76/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.2144\n",
            "Epoch 77/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.2082\n",
            "Epoch 78/100\n",
            "31/31 [==============================] - 3s 99ms/step - loss: 0.2019\n",
            "Epoch 79/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.1961\n",
            "Epoch 80/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.1911\n",
            "Epoch 81/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1854\n",
            "Epoch 82/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1801\n",
            "Epoch 83/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1755\n",
            "Epoch 84/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1692\n",
            "Epoch 85/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.1648\n",
            "Epoch 86/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1602\n",
            "Epoch 87/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.1548\n",
            "Epoch 88/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1506\n",
            "Epoch 89/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1461\n",
            "Epoch 90/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1417\n",
            "Epoch 91/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.1374\n",
            "Epoch 92/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.1329\n",
            "Epoch 93/100\n",
            "31/31 [==============================] - 3s 101ms/step - loss: 0.1294\n",
            "Epoch 94/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.1251\n",
            "Epoch 95/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.1211\n",
            "Epoch 96/100\n",
            "31/31 [==============================] - 3s 102ms/step - loss: 0.1174\n",
            "Epoch 97/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.1139\n",
            "Epoch 98/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.1099\n",
            "Epoch 99/100\n",
            "31/31 [==============================] - 3s 100ms/step - loss: 0.1066\n",
            "Epoch 100/100\n",
            "31/31 [==============================] - 3s 98ms/step - loss: 0.1031\n",
            "Training time: {320.16886353492737} s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JbO5yoEe0YjM"
      },
      "source": [
        "## **3) Inferencing on the models**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2jL1TpDZ0-NE"
      },
      "source": [
        "def make_inference_models():\n",
        "    \n",
        "    encoder_model = tf.keras.models.Model(encoder_inputs, encoder_states)\n",
        "    \n",
        "    decoder_state_input_h = tf.keras.layers.Input(shape=( 128 ,))\n",
        "    decoder_state_input_c = tf.keras.layers.Input(shape=( 128 ,))\n",
        "    \n",
        "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "    \n",
        "    decoder_outputs, state_h, state_c = decoder_lstm(\n",
        "        decoder_embedding , initial_state=decoder_states_inputs)\n",
        "    decoder_states = [state_h, state_c]\n",
        "    decoder_outputs = decoder_dense(decoder_outputs)\n",
        "    decoder_model = tf.keras.models.Model(\n",
        "        [decoder_inputs] + decoder_states_inputs,\n",
        "        [decoder_outputs] + decoder_states)\n",
        "    \n",
        "    return encoder_model , decoder_model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtOPbaVm1HEV"
      },
      "source": [
        "## **4) Making some translations**\n",
        "\n",
        "\n",
        "1.   First, we take a Vietnamese sequence and predict the state values using `enc_model`.\n",
        "2.   We set the state values in the decoder's LSTM.\n",
        "3.   Then, we generate a sequence which contains the `<start>` element.\n",
        "4.   We input this sequence in the `dec_model`.\n",
        "5.   We replace the `<start>` element with the element which was predicted by the `dec_model` and update the state values.\n",
        "6.   We carry out the above steps iteratively till we hit the `<end>` tag or the maximum sequence length.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HED7mM9i0-T2"
      },
      "source": [
        "def str_to_tokens( sentence : str ):\n",
        "    words = sentence.lower().split()\n",
        "    tokens_list = list()\n",
        "    for word in words:\n",
        "        tokens_list.append( vie_word_dict[ word ] ) \n",
        "    return preprocessing.sequence.pad_sequences( [tokens_list] , maxlen=max_input_length , padding='post')"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3VGaEJn0-XS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b147748f-cff0-4d90-f587-8197dbd6c33f"
      },
      "source": [
        "\n",
        "enc_model , dec_model = make_inference_models()\n",
        "\n",
        "for epoch in range( encoder_input_data.shape[0] ):\n",
        "    states_values = enc_model.predict( str_to_tokens( input( 'Enter vie sentence : ' ) ) )\n",
        "    #states_values = enc_model.predict( encoder_input_data[ epoch ] )\n",
        "    empty_target_seq = np.zeros( ( 1 , 1 ) )\n",
        "    empty_target_seq[0, 0] = eng_word_dict['start']\n",
        "    stop_condition = False\n",
        "    decoded_translation = ''\n",
        "    while not stop_condition :\n",
        "        dec_outputs , h , c = dec_model.predict([ empty_target_seq ] + states_values )\n",
        "        sampled_word_index = np.argmax( dec_outputs[0, -1, :] )\n",
        "        sampled_word = None\n",
        "        for word , index in eng_word_dict.items() :\n",
        "            if sampled_word_index == index :\n",
        "                decoded_translation += ' {}'.format( word )\n",
        "                sampled_word = word\n",
        "        \n",
        "        if sampled_word == 'end' or len(decoded_translation.split()) > max_output_length:\n",
        "            stop_condition = True\n",
        "            \n",
        "        empty_target_seq = np.zeros( ( 1 , 1 ) )  \n",
        "        empty_target_seq[ 0 , 0 ] = sampled_word_index\n",
        "        states_values = [ h , c ] \n",
        "\n",
        "    print( decoded_translation )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Enter vie sentence : xin chào bạn\n",
            " hello may end\n",
            "Enter vie sentence : bạn có khỏe không\n",
            " do you have any choice end\n",
            "Enter vie sentence : tôi rất thích bạn\n",
            " i like oranges very much end\n",
            "Enter vie sentence : tôi thấy hoa vàng trên cỏ xanh\n",
            " i saw it hard end\n",
            "Enter vie sentence : sự thật luôn chỉ có một\n",
            " that's always a bad person end\n",
            "Enter vie sentence : tiếp tục đi\n",
            " keep looking end\n",
            "Enter vie sentence : chạy\n",
            " run end\n",
            "Enter vie sentence : chạy ngay\n",
            " just run end\n",
            "Enter vie sentence : chạy ngay đi\n",
            " go to go home end\n",
            "Enter vie sentence : nắm lấy tay anh\n",
            " it's up to a mistake end\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbkQ9PZZdcNc"
      },
      "source": [
        "- ***Comment***: We see that the translated words still do not match the content to be translated. The reason is that our dataset is still not enough to be able to learn well."
      ]
    }
  ]
}